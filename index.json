{
  "about/core-beliefs.html": {
    "href": "about/core-beliefs.html",
    "title": "| Composable",
    "keywords": "Core beliefs We believe that if you are considering using our tools you really should read all of this page to determine if it is likely to be a good fit for you and your organization. You may have trouble seeing the relevance at first, but it should all fit together as a whole in the end. We believe that people should always be a vital consideration:: We believe that our level of success of failure in collaborative endeavors hinges more on the humans, relationships and cultures involved than on any other factor. On how well we collaborate, communicate, motivate etc. We believe that this in turn hinges on our understanding of ourselves, on our understanding of human nature, on our understanding of the human mind and its properties, strengths and weaknesses. We believe that this understanding must include our drives, instincts, emotions and feelings. We believe that whenever we lose sight of this as a vital consideration when making choices we are likely to make choices with poor outcomes. This includes software design choices. We believe in the necessity of accepting complexity and letting go of certainty:: We believe we all instinctively prefer simplicity, certainty and absolutes. That this is a trait that was likely adaptive when we lived as hunter gatherers. We believe that this is no longer a primarily adaptive trait. We believe that succumbing to this trait cripples our ability to see the true complexity of the reality we have before us. Rather than clear cut wrong and right ways to do things we believe that we face great complexity and a great amount of possible choices in every situation. We believe that we must accept the weight of the uncertainty of this reality in order to make good choices. We believe in the superiority of motivated belief over dichotomies and absolutes:: We believe that succumbing to the desire to think and debate in terms of simple good versus bad dichotomies or absolutes such as \"best way\" is crippling. That it cripples not only our own understanding, but even more so our ability to collaborate in teams and larger communities. We believe that it is far better to say: \"We believe\" and then motivate that belief, than to state something as a fact without motivation. We believe that we must resist the temptation to talk about good versus bad and wrong versus right. We believe that there is no such thing as a \"best\" way to do anything, rather every option has a complex set of consequences in any specific set of circumstances which we never fully understand. We believe that we should abandon the false simplicity of right versus wrong dichotomies and absolutes such as \"best\". We believe that development should focus on shared mental models designed for humans:: We believe that developing software is first and foremost a process of collaboratively designing and communicating shared mental models. We believe that our focus must be on the quality and clarity of our mental models and the clarity and expressiveness of the code that we use to communicate these mental models to each other and our future selves. That the quality of a design is determined by how easily the totality of the mental models that it contains can be learned, communicated, and modified by human beings. We believe that the primary limiting factor is the mental burden imposed by the totality of our shared mental models:: We believe that in the majority of software development situations a lack of focus on the quality of the mental models is ultimately the primary factor limiting progress. That progress slows and ultimately stalls when the totality of our mental models fall into a state where the humans developing them can no longer effectively learn, understand, modify and communicate them. We believe that if we continually refactor our mental models to fit the human mind it is possible to maintain progress indefinitely without stalling and with limited slowdown even when facing immensely complicated software. We believe that this is the implicit principle underpinning approaches such as Domain Driven Design and principles such as SOLID."
  },
  "about/design-principles.html": {
    "href": "about/design-principles.html",
    "title": "| Composable",
    "keywords": "Design Principles Strive to minimize total mental burden Over minimizing initial learning effort Over minimizing local complexity Over minimizing lines of code Over minimizing component complexity Over maximizing performance Over maximizing scalability"
  },
  "about/faq.html": {
    "href": "about/faq.html",
    "title": "| Composable",
    "keywords": "How stable is Composable? The event store and the document database have been proven in production for a number of years. The current code has only minor changes. The service bus is new, under development, and untried in production. Of course all the components have test suites. No component has known bugs. We normally prioritize bug fixes over all feature development. What type of infrastructure does Composable require? Composable uses a relational database for all storage. Currently, supported databases are Sql Server, PostgreSql and MySql. Other than a Sql instance composable components have no special requirements. Performance & scalability How well does Composable components perform? Very well and it will only get better. We have spent a ton of effort making sure that both performance and scalability is as high as possible without sacrificing reliability, productivity and maintainability. We have automated performance degradation tests that run continuously as we develop. We continuously look for ways to make things even faster and as we do we adjust the tests to require the new level of performance that we have achieved. What if we need extreme querying scalability? Given this requirement we assume that you are willing to sacrifice some level of consistency in query results. These are then possible options: Maintain query models in any storage with sufficient scalablility. Add a layer on top of your querying API that makes use of a distributed cache. What if we need extreme write side scalability? If only a small subset of your data requires this level of write scalability, consider implementing only that part using other tools. If most of your data requires that level of scalability we would not recommend using our tools. Reliability Why do you enforce transactions for all updates? Because it is our opinion that without transactions you have to sacrifice either reliability or simplicity/maintainability and we prioritize those over scalability and performance. Why do you enforce exactly once delivery for domain events? Because it is our opinion that without exactly once delivery you have to sacrifice either reliability or simplicity/maintainability and we prioritize those over scalability and performance. I've heard that exactly once delivery is impossible... All arguments to that effect that we have encountered reason by disallowing transactions and/or message deduplication. Only through imposing this artificial constraint does exactly once delivery become \"impossible\". Exactly once == at least once + deduplication + transactions."
  },
  "about/index.html": {
    "href": "about/index.html",
    "title": "| Composable",
    "keywords": "= About :page-permalink: /about/ :page-toc: :doctype: book :imagesdir: images :source-highlighter: highlightjs :highlightjs-theme: agate include::core-beliefs.adoc[] include::design-principles.adoc[] include::primary-architectural-choices.adoc[]"
  },
  "about/primary-architectural-choices.html": {
    "href": "about/primary-architectural-choices.html",
    "title": "| Composable",
    "keywords": "Primary architectural choices We require you to learn a \"new\" modelling paradigm, semantic events:: We do not believe that we would be able to build highly complicated software using a language that did not support a flexible modelling paradigm, such as object oriented programming, without great loss of productivity, simplicity and safety. We believe that such standardized modelling paradigms enable us to successfully manage far greater levels of complexity than we could without them. This is what we aim to achieve by ubiquitously leveraging the semantic event modeling paradigm throughout our tools. Using the existing interface support in C# we enable you to model a highly complicated domain in terms of which events can occur and how the meanings of these events relate to each other, the aggregate root to which they belong, and to other abstractions in the domain. The same modelling paradigm is utilized at all levels of design. From the smallest component or entity nested in an aggregate to designing and implementing the highest level integrations in an ecosystem of integrated systems. Our experience is that this new modelling paradigm, this new view of your domain and ecosystem of domains, is highly beneficial to managing and scaling complexity of the domains and integrations between them. We also find it highly beneficial in communicating with with domain experts. It has given us an expressive way of viewing a system in terms of what can happen, without getting bogged down in the details of how. On the technical side it enables us to dramatically cut down on manual code and manual configuration. It enables us to build complicated aggregates, read models, and message based integrations with simple, SOLID, expressive code. All with zero manual routing code or configuration to take into consideration. You can use the same powerful mental model to understand how everything will work at all levels instead of having to design and remember countless custom routes within aggregates and within the bus. Our experience is that this as a whole dramatically reduces the total mental burden of understanding a large system or ecosystem of systems. Our experience is that it allows us to scale to far greater complexity of a domain and exposed features without development slowing or virtually stalling due to the runaway mental burden of an implementation that does not leverage a powerful modelling paradigm. We enforce the use of transactions for all domain data updates:: We enforce the use of exactly once delivery for domain events and commands::"
  },
  "docs/_sections/components/event-store/basics.html": {
    "href": "docs/_sections/components/event-store/basics.html",
    "title": "| Composable",
    "keywords": "Event Store Basics Aggregate Roots The Event Store Session Saving and loading aggregate roots."
  },
  "docs/_sections/components/event-store/refactoring.html": {
    "href": "docs/_sections/components/event-store/refactoring.html",
    "title": "| Composable",
    "keywords": "Refactoring Event Streams"
  },
  "docs/messaging/basics.html": {
    "href": "docs/messaging/basics.html",
    "title": "Messaging Basics | Composable",
    "keywords": "Messaging Basics Note The code blocks in this section contain pseudocode for illustration purposes. It is not compatible with any specific library including Composable. Messaging Any method call can, if you squint, be viewed as one object sending a message to another object. However, this ties the sender tightly to the receiver. Loose coupling benefits can be had by making the message passing explicit. By sending messages to a receiver through some intermediary rather than directly. Doing so is called messaging. Tip Messaging is also known as message passing. Messaging terms Here we define some terms as they are used in the context of this document. Message An object for the purpose of sending data to a receiver. Message Type The System.Type returned by message.GetType(). Message Handler In principle just a function that takes a message as a parameter. void Handle(RegisterAccountCommand command); In practice most message handlers need to have one or more dependencies injected into them. In order to support this handlers are often required to be wrapped inside interfaces. That way instances of implementing classes can be resolved from an IOC container easily. interface IMessageHandler<RegisterAccountCommand> { void Handle(RegisterAccountCommand aMessage); } Routing The mechanism by which messages are delivered to handlers. Service Bus A component which decouples message senders from message handlers. Instead of client code calling handler methods, clients send and receive messages via the bus. The bus is responsible for routing the messages to the appropriate handler(s) and invoking them. .Manual service invocation requires an instance of the service. serviceInstance.RegisterAccount(arguments.... .Client don't even know where the service is when accessing it across a bus bus.Send(new RegisterAccountCommand( Tip The benefits of this decoupling may not be obvious at first, but they are profound. Command A message that instructs the handler to perform an action. class RegisterAccountCommand { AccountId AccountId { get; } Password Password { get; } Email Email { get; } } Event A message that informs handlers about something that has happened. interface IAccountRegisteredEvent { AccountId AccountId { get; } Password Password { get; } Email Email { get; } } Query A message that asks the handler to supply some data. class RecentlyRegisteredAccountsQuery { TimeSpan MaxAge { get; } } Command Handler A message handler for a command. Must ensure that the command is successfully executed or throw an exception. Query Handler A message handler for a query. Must ensure that the query is successfully executed or throw an exception. Event Handler A message handler for an event. Event Listener Synonym of Event Handler. Subscribe The action of registering an Event Handler with a service bus. Subscriber An event handler registered on a service bus. Sending a command or query Asking a service bus to deliver a message to its handler. Publishing an event Delivering an event to all it's subscribers. Raising an event Same as Publishing an event Tip You always publish/Raise events. Keeping Send separate from Publish in your mind is fundamental to understanding."
  },
  "docs/messaging/semantic-routing.html": {
    "href": "docs/messaging/semantic-routing.html",
    "title": "Semantic Routing | Composable",
    "keywords": "Semantic Routing NOTE: Semantic routing is used throughout the toolkit. It is foundational for the Event Store, Service Bus, Query Model updaters and Generators... Definition Events are delivered to every registered handler with a compatible argument type. Commands and query message types must have exactly one handler. Tip The first rule is really just polymorphism. Tip Semantic Routing is also known as \"Polymorphic routing\" or \"Polymorphic dispatching\". Clarifying examples Given these event interfaces and implementing classes interface IA interface IB : IA interface IC : IB class A : IA {} class B : IB {} class C : IC {} And these handler methods registered on our service bus void HandleA(IA ia){} //Handles IA, IB and IC void HandleB(IB ib){} //Handles IB and IC void HandleC(IC ic){} //Handles only IC .Let's publish some events and examine the results. serviceBus.Publish(new A()); //Delivered to HandleA serviceBus.Publish(new B()); //Delivered to HandleA and HandleB serviceBus.Publish(new C()); //Delivered to HandleA, HandleB and HandleC Loose coupling through interfaces Working with events in terms of interfaces maintains flexibility. Here is a partial list of things it is possible to do without having to change any code in any event listener. Refactoring event classes Adding event classes Adding event interfaces Changing event inheritance hierarchy Tip Remember to think about events in terms of interfaces. The event classes are an implementation detail that should only ever be known by the code that publishes the event. Warning Do not subscribe to event classes. You will lose the benefits just discussed."
  },
  "index.html": {
    "href": "index.html",
    "title": "Modern architecture for normal projects | Composable",
    "keywords": "Modern architecture for normal projects Composable provides tooling for normal modern architecture projects. Modern architectures By modern architecture we mean software that tend to use tools or designs with labels such as Event Driven Architecture, Event Driven SOA, CQRS, Microservices, NoSql, Event Sourcing etc. Normal projects By normal projects we mean the vast majority of projects. Projects where reliability, productivity and maintainability are the top priorities. Projects where extreme scalability and availability are not required. Existing tooling and platforms Unfortunately, it seems to us that most modern architecture tooling and platforms do not target normal projects. Instead they sacrifice reliability on the altar of nominal scalability and availability. In our experience this tends to result in a complexity explosion as the developers try to build reliable software with tooling not designed for reliability. Ultimately scalability and availability often disappear along with both productivity and maintainability as the complexity skyrockets. How Composable components are different Composable consistently prioritizes reliability, productivity and maintainability for normal projects. Therefore all our tools fully support the following: Transactions and TransactionScope. High performance black box testing using the real production components. Renaming and moving classes already persisted in production data without breaking production data Renaming properties and fields without breaking production data (using Newtonsoft.Net attributes) Powerful semantic event modelling paradigm Compile time and runtime design validation catching all known common design mistakes. link:about/faq#performance[All the performance and scalability that we can squeeze out] Hypermedia Service Bus A unified messaging platform that gives you Powerful zero configuration routing A service bus with an exactly-once delivery guarantee RPC style communication with optional command deduplication Letting you build Type safe Hypermedia APIs that can be consumed with with full intellisense and type safety in .Net language clients such as ASP.Net or Blazor (Blazor support not yet implemented) Typescript (Not yet implemented) All the features from How Composable components are different Event Store Build complex aggregates nesting entities and components in each other to arbitrary depths with ease by leveraging semantic events. Refactoring of event histories including fully removing obsolete code Performant on-demand generation of query models from events dramatically reduces the need for persisted query models All the features from How Composable components are different Document Database Save or load instances of any class serializable with Newtonsoft.Json with a single line of code. Automatically tracks and persists changes to loaded documents All the features from How Composable components are different Hypermedia API Most APIs consist of a number of service classes and interfaces. Imagine instead an APIs that is a lot like a website. That had a start resource from which you follow links to other resources where you could fill in commands and post them. That is essentially what a Hypermedia API is. Hypermedia API have these advantages among others: You expose zero implementation details about your API. Clients only know about the hypermedia controls such as commands, resources and links. Developers don't need to read a ton of documentation to figure out how to use your API or what functionality is available. Instead they just follow the links using intellisense from your start-resource to explore the functionality. Semantic event modelling paradigm Simply means that you declare how the meaning of one event relates to the meaning of another through .Net interface inheritance. As it turns out this enables very flexible and powerful domain designs with complex aggregates, zero configuration routing and elimination of a ton of duplicated event handler code."
  }
}